# Yayue Hou (侯雅玥)
Yayue Hou is currently a PhD student of Rensselaer Polytechnique Institute.
- **Yayue Hou is currently looking for 2026 Summer Internship.**

## Research Interests
- Algorithms and Hardware co-design for machine learning systems. 
- Compute-in-Memory, including algorithm improvement and hardware efficiency enhancement.
- Noise resilient analog foundation models with new model architecture and training techniques.

## Publications
- DATE'25, **Yayue Hou**, Hsinyu Tsai, Kaoutar El Maghraoui, Tayfun Gokmen, Geoffrey W. Burr, Liu Liu. "NORA: Noise-Optimized Rescaling of LLMs on Analog Compute-in-Memory Accelerators." In Proceedings of Design, Automation and Test in Europe Conference, 2025
- ICCAD'25, **Yayue Hou**, Zhenyu Liu, Garrett Gagnon, Hsinyu Tsai, Kaoutar El Maghraoui, Geoffrey W. Burr, Liu Liu. "SAGE: Saliency-Aware Grouping for Efficient Mapping of LLMs on Analog Compute-in-Memory." In upcoming 2025 International Conference on Computer-Aided Design.

## Skills
- Programming: Python, Verilog, VHDL, C/C++, CUDA
- Tools & Frameworks: PyTorch, Anaconda, Huggingface, AIHWKIT (Analog CIM), CACTI, Synopsys, Cadence, LaTeX.
- Familiar areas: In-Memory-Computing, Sparsity, Quantization, Parameter-Efficient Fine-Tuning, Hardware-Software Co-design.

## Education
- 2023-present, Rensselaer Polytechnic Institute, NY. Ph.D. student in Electrical Engineering.
- 2019-2023, Tongji University, Shanghai. B.Eng. in Microelectronics Science and Engineering.

## Research Experiences
- 2025-present, Parameter-efficient Model Fine-tuning on Analog Compute-in-Memory Devices.
  * Keywords: Analog CIM, Fine-tuning, Noise resilient model
  * Summary: We design a framework for LLM fine-tuning on Analog Compute-in-Memory devices, which considers limited endurance and high programming overhead of ACIM memory devices and flexibility of LLM deployment on difference ACIM systems.
- 2025-present, Efficient Compute-in-memory Heterogeneous System for LLMs and MoE.
  * Keywords: Analog CIM, MoE, Heterogeneous CIM system
  * Summary: We apply a highly heterogeneous system integrating analog CIM, digital CIM, and conventional digital units. We design a management mechanism to balance workloads across different computing units and fully utilize bandwidth and compute resources.
- 2024-2025, Noise-aware Analog Compute-in-Memory Algorithm-Hardware Co-design for LLMs.
  * Keywords: Analog CIM, LLM, Post-training, ADC energy efficiency
  * Summary: We analyze the performance of LLMs under different Analog CIM noises and propose calibration techniques which increase model resilience and enable lower ADC working precision by managing the weight and activation data distribution of LLMs. 
- 2023-2024, Efficient Architecture Design for LLM Inference.
  * Keywords: LLM Sparsity, Heterogeneous Computing System, Energy Efficiency
  * Summary: To alleviate the overhead caused by random access patterns in sparse attention, we try to build up structured sparsity patterns and apply them to LLM attention layers.
